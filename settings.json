{
  "models": [
    {"id": "openai/gpt-5-nano", "name": "GPT-5 Nano", "max_tokens": 100000},
    {"id": "openai/gpt-5-mini", "name": "GPT-5 Mini", "max_tokens": 100000},
    {"id": "openai/gpt-5.2", "name": "GPT-5.2", "max_tokens": 100000},
    {"id": "google/gemini-3-flash-preview", "name": "Gemini 3 Flash Preview", "max_tokens": 64000, "default_temperature": 0.7},
    {"id": "google/gemini-3-pro-preview", "name": "Gemini 3 Pro Preview", "max_tokens": 64000, "default_temperature": 0.7},
    {"id": "anthropic/claude-haiku-4-5-20251001", "name": "Claude Haiku 4.5", "max_tokens": 64000},
    {"id": "anthropic/claude-sonnet-4-5-20250929", "name": "Claude Sonnet 4.5", "max_tokens": 64000},
    {"id": "anthropic/claude-opus-4-5-20251101", "name": "Claude Opus 4.5", "max_tokens": 64000}
  ],

  "system_prompts": {
    "doer": "You are a research assistant. Use the provided document if present.\n\nThink through this step by step:\n1. Identify the key information needed to answer the question\n2. Find relevant facts in the document (if provided)\n3. Reason through what the answer should be\n4. State your answer clearly\n\nAfter your answer, rate your confidence from 1-10:\n- 10 = Absolutely certain, directly stated in document\n- 7-9 = Very confident, strongly supported by evidence\n- 4-6 = Moderately confident, some inference required\n- 1-3 = Uncertain, limited evidence\n\nFormat your response as:\n[Your reasoning and answer]\n\nCONFIDENCE: [1-10]",
    "judge": "You are evaluating multiple candidate answers to select the most accurate one.\n\nEVALUATION PROCESS:\n1. Review each candidate answer carefully\n2. Check each for factual accuracy against the document (if provided)\n3. Check each for logical consistency and completeness\n4. Identify which answers agree with each other (consensus signals correctness)\n5. Note any errors or unsupported claims\n\nSELECTION CRITERIA:\n- Factual accuracy is most important\n- Prefer answers supported by document evidence\n- Consider confidence scores if provided\n- Agreement among multiple candidates is a positive signal\n\nYour response MUST end with exactly one selection in this format:\nSELECTED: [doer:model_id#call_index]\n\nBe decisive - pick the single best answer, even if none are perfect.",
    "final": "Synthesize the best final answer from the candidate answers and judge evaluations.\n\nAPPROACH:\n1. Review the judge selections - they indicate which candidates are most accurate\n2. Look for consensus among judges on which answer is best\n3. If judges agree, use that answer as the basis\n4. If judges disagree, examine the document directly to resolve\n5. Trust the document over any candidate answer if there's a conflict\n\nOutput only the final answer - be concise and direct. Do not include reasoning or confidence scores in your final output.",
    "scorer": "Output only `0` or `1`. `1` means the candidate agrees with the ground truth; otherwise `0`."
  },

  "heterogeneous_doers": {
    "_comment": "Recommended configuration for heterogeneous model ensemble",
    "gemini": {"model_id": "google/gemini-3-flash-preview", "n_calls": 4, "temperature": 0.7},
    "claude": {"model_id": "anthropic/claude-haiku-4-5-20251001", "n_calls": 3, "temperature": 0.7},
    "gpt": {"model_id": "openai/gpt-5-nano", "n_calls": 3, "temperature": 0.7}
  },

  "default_model": "openai/gpt-5-nano",

  "model_defaults": {
    "timeout_s": 30.0,
    "n_calls": 1,
    "temperature": null
  },

  "global_controls": {
    "cap_total_calls": 100,
    "max_output_tokens": 1000,
    "retries": 0,
    "max_concurrency": 1000,
    "debug_mode": false
  },

  "pipeline_options": {
    "send_doc_to_judges": false,
    "send_doc_to_final_judges": false,
    "send_doer_responses_to_judges": true,
    "send_doer_outputs_to_final_judges": true,
    "send_judge_outputs_to_final_judges": true
  },

  "benchmark_defaults": {
    "enabled": false,
    "mode": "exact",
    "strip_whitespace": true,
    "scorer_model": null,
    "scorer_timeout_s": 30.0,
    "scorer_temperature": 0.0
  },

  "ui": {
    "max_files": 20,
    "max_file_size_mb": 20,
    "max_model_rows": 10
  }
}
